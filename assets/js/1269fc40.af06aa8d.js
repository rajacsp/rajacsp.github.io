"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[91548],{34668:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>c,contentTitle:()=>k,default:()=>l,frontMatter:()=>s,metadata:()=>o,toc:()=>i});const o=JSON.parse('{"id":"technologies/kafka/kafka-commands","title":"Kafka Commands","description":"Configuration","source":"@site/docs/technologies/kafka/kafka-commands.md","sourceDirName":"technologies/kafka","slug":"/technologies/kafka/kafka-commands","permalink":"/technologies/kafka/kafka-commands","draft":false,"unlisted":false,"editUrl":"https://github.com/rajacsp/rajacsp.github.io/tree/master/docs/technologies/kafka/kafka-commands.md","tags":[],"version":"current","lastUpdatedBy":"Deepak Sood","lastUpdatedAt":1729278358000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Kafka Architecture","permalink":"/technologies/kafka/kafka-architecture"},"next":{"title":"Kafka Connect","permalink":"/technologies/kafka/kafka-connect"}}');var t=n(474848),r=n(28453);const s={},k="Kafka Commands",c={},i=[{value:"Configuration",id:"configuration",level:2},{value:"CloudFormation template",id:"cloudformation-template",level:2},{value:"Kafka confluent single node client setup",id:"kafka-confluent-single-node-client-setup",level:2},{value:"Others",id:"others",level:2}];function p(e){const a={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(a.header,{children:(0,t.jsx)(a.h1,{id:"kafka-commands",children:"Kafka Commands"})}),"\n",(0,t.jsx)(a.h2,{id:"configuration",children:"Configuration"}),"\n",(0,t.jsx)(a.p,{children:(0,t.jsx)(a.a,{href:"https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION",children:"https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION"})}),"\n",(0,t.jsx)(a.h2,{id:"cloudformation-template",children:"CloudFormation template"}),"\n",(0,t.jsx)(a.p,{children:(0,t.jsx)(a.a,{href:"https://aws-quickstart.s3.amazonaws.com/quickstart-confluent-kafka/templates/confluent-kafka.template",children:"https://aws-quickstart.s3.amazonaws.com/quickstart-confluent-kafka/templates/confluent-kafka.template"})}),"\n",(0,t.jsx)(a.h2,{id:"kafka-confluent-single-node-client-setup",children:"Kafka confluent single node client setup"}),"\n",(0,t.jsx)(a.p,{children:(0,t.jsx)(a.a,{href:"https://docs.confluent.io/current/installation/docker/docs/installation/single-node-client.html",children:"https://docs.confluent.io/current/installation/docker/docs/installation/single-node-client.html"})}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-bash",children:'## Create docker network\ndocker network create confluent\n\n## Start Zookeeper\ndocker run -d --net=example-docker --name=zookeeper -e ZOOKEEPER_CLIENT_PORT=2181 confluentinc/cp-zookeeper:5.1.0\n\n## Start Confluent Kafka\ndocker run -d\n--net=example-docker\n--name=kafka -p 9092:9092\n-e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181\n-e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092\n-e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1\nconfluentinc/cp-kafka:5.1.0\n\n## Create topic\ndocker run\n--net=example-docker\n--rm confluentinc/cp-kafka:5.1.0\nkafka-topics --create --topic smap_telemetry_data --partitions 3 --replication-factor 1 --config retention.ms=-1\n--if-not-exists --zookeeper zookeeper1:2181,zookeeper2:2182,zookeeper3:2183\n\n## Alter topic\ndocker run\n--net=example-docker\n--rm confluentinc/cp-kafka:5.1.0\nkafka-topics --alter --topic smap_telemetry_data --partitions 3 -config retention.ms=-1 --zookeeper zookeeper1:2181,zookeeper2:2181,zookeeper3:2181\n\ndocker run\n--net=example-docker\n--rm confluentinc/cp-kafka:5.1.0\nkafka-topics --alter --topic iot_data --config retention.ms=-1 --zookeeper zookeeper1:2181,zookeeper2:2181,zookeeper3:2181\n\n## Delete topic\n# Topic is marked for deletion and if kafka is configured with KAFKA_DELETE_TOPIC_ENABLE:"true" then it is deleted\n\ndocker run\n--net=example-docker\n--rm\nconfluentinc/cp-kafka:5.1.0\n\nkafka-topics --delete --topic _schemas --zookeeper zookeeper1:2181,zookeeper2:2182,zookeeper3:2183\n\n## Show all Topics\ndocker run\n--net=example-docker\n--rm\nconfluentinc/cp-kafka:5.1.0\nkafka-topics --describe --zookeeper zookeeper1:2181,zookeeper2:2182,zookeeper3:2183\n\ndocker run\n--net=example-docker\n--rm\nconfluentinc/cp-kafka:5.1.0\nkafka-topics --describe --topic smap_telemetry_data --zookeeper zookeeper1:2181,zookeeper2:2182,zookeeper3:2183\n\ndocker run\n--net=example-docker\n--rm\nconfluentinc/cp-kafka:5.1.0\nkafka-topics --describe --topic smap_telemetry_data --zookeeper zookeeper1:2181,zookeeper2:2182,zookeeper3:2183\n\n## Start confluent kafka control center\ndocker run -d\n--name=control-center\n--net=example-docker\n--ulimit nofile=16384:16384\n-p 9021:9021\n-v /tmp/control-center/data:/var/lib/confluent-control-center\n-e CONTROL_CENTER_ZOOKEEPER_CONNECT=zookeeper:2181\n-e CONTROL_CENTER_BOOTSTRAP_SERVERS=kafka:9092\n-e CONTROL_CENTER_REPLICATION_FACTOR=1\n-e CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS=1\n-e CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS=1\n-e CONTROL_CENTER_STREAMS_NUM_STREAM_THREADS=2\n-e CONTROL_CENTER_CONNECT_CLUSTER=http://kafka-connect:8082\nconfluentinc/cp-enterprise-control-center:5.1.0\n\n## Create data\ndocker run\n--net=example-docker\n--rm\nconfluentinc/cp-kafka:5.1.0\nbash -c "seq 42 | kafka-console-producer --request-required-acks 1\n--broker-list kafka1:19091,kafka2:19092,kafka3:19093 --topic smap_telemetry_data && echo \'Produced 42 messages.\'"\n\n## Receive data\ndocker run\n--net=example-docker\n--rm\nconfluentinc/cp-kafka:5.1.0\nkafka-console-consumer --bootstrap-server kafka1:19091,kafka2:19092,kafka3:19093 --topic smap_telemetry_data --from-beginning\n\n# kafka.example.com - 9091,9092,9093\ndocker run\n--net=example-docker\n--rm\nconfluentinc/cp-kafka:5.1.0\nkafka-console-consumer --bootstrap-server kafka.example.com:9091,kafka.example.com:9092,kafka.example.com:9093 --topic dev_smap_telemetry_data --from-beginning\n\n# consume druid_telemetry_data\ndocker run\n--net=example-docker\n--rm\nconfluentinc/cp-kafka:5.1.0\nkafka-console-consumer --bootstrap-server kafka.example.com:9091,kafka.example.com:9092,kafka.example.com:9093 --topic druid_telemetry_data --from-beginning\n\n## Show consumer group offsets\nkafka-consumer-groups --bootstrap-server kafka1:19091,kafka2:19092,kafka3:19093 --list\n\nkafka-consumer-groups --bootstrap-server ke-cp-kafka-headless:9092 --describe --group kafka_influx_republisher_group\n\nkafka-consumer-groups --bootstrap-server kafka1:19091,kafka2:19092,kafka3:19093 --describe --group kafka_druid_republisher_group\n\n## Kafka Configs\n## Describe a topic\n\nkafka-configs --bootstrap-server ke-cp-kafka-headless:9092 --entity-type brokers --entity-default --describe\nkafka-configs --zookeeper ke-cp-zookeeper-headless:2181 --entity-type topics --entity-name smap_telemetry_data --describe\n\n## Add config\nkafka-configs --zookeeper ke-cp-zookeeper-headless:2181 --entity-type topics --entity-name smap_telemetry_data --alter --add-config retention.ms=604800000\n\nkafka-configs --zookeeper ke-cp-zookeeper-headless:2181 --entity-type topics --entity-name druid_telemetry_data --alter --add-config retention.ms=172800000\n\nkafka-configs --zookeeper ke-cp-zookeeper-headless:2181 --entity-type topics --entity-name test_smap_telemetry_data --alter --add-config retention.ms=172800000\n\nkafka-configs --zookeeper ke-cp-zookeeper-headless:2181 --entity-type topics --entity-name dev_druid_telemetry_data --alter --add-config retention.ms=172800000\n\n## Barebones Command\n\n## Installing and running\n\nbrew update\n\nbrew cask install caskroom/versions/java8\n\nbrew install kafka\n\n## Start zookeeper server\nzkserver start\n\nbin/zookeeper-server-start.sh config/zookeeper.properties &\n\n## Stop zookeeper server\nbin/zookeeper-server-stop.sh\n\n## Start kafka server\nsh /usr/local/Cellar/kafka/2.0.0/bin/kafka-server-start /usr/local/etc/kafka/server.properties\n\nbin/kafka-server-start.sh config/server.properties &\n\n## Stop kafka server\nbin/kafka-server-stop.sh\n\n## Create Topic\nsh /usr/local/Cellar/kafka/2.0.0/bin/kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n\nbin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n\n## List all topics\nsh /usr/local/Cellar/kafka/2.0.0/bin/kafka-topics --list --zookeeper localhost:2181\n\nbin/kafka-topics.sh --list --zookeeper localhost:2181\n\n## Start producer\nsh /usr/local/Cellar/kafka/2.0.0/bin/kafka-console-producer --broker-list localhost:9092 --topic test\n\nbin/kafka-console-producer.sh --broker-list localhost:9092 --topic test\n\n## Start consumer\nsh /usr/local/Cellar/kafka/2.0.0/bin/kafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginning\n\nbin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning\n\n## RPI\nwget http://mirrordirector.raspbian.org/raspbian/pool/main/libr/librdkafka/librdkafka-dev_0.9.3-1_armhf.deb\n\nsudo dpkg -i librdkafka-dev_0.9.3-1_armhf.deb\n\nsudo apt-get install -f\n\nsudo apt-get install libstdc++6\n\n## Other commands\n- ./kafka-topics.sh --create --bootstrap-server my-cluster-kafka-brokers.kafka:9092 --replication-factor 2 --partitions 3 --topic test_bank_data --config compression.type="snappy"\n- ./kafka-topics --describe --topic _schemas4 --zookeeper localhost:2181\n- ./kafka-console-producer --broker-list localhost:9092 --topic test\n- ./kafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginning\n\n## Kafka Commands (inside docker container)\n\ncd /usr/bin\n\nkafka-acls\nkafka-broker-api-versions\nkafka-configs\nkafka-console-consumer\nkafka-console-producer\nkafka-consumer-groups\nkafka-consumer-perf-test\nkafka-delegation-tokens\nkafka-delete-records\nkafka-dump-log\nkafka-log-dirs\nkafka-mirror-maker\nkafka-preferred-replica-election\nkafka-producer-perf-test\nkafka-reassign-partitions\nkafka-replica-verification\nkafka-run-class\n\nbin/kafka-run-class.sh kafka.tools.DumpLogSegments --files /var/lib/kafka/data-0/kafka-log0/test/00000000000000000000.log --print-data-log | grep compresscodec\n\nkafka-server-start\nkafka-server-stop\nkafka-streams-application-reset\nkafka-topics\nkafka-verifiable-consumer\nkafka-verifiable-producer\n\n## Explore with kafka commands\n\n# kafka version\nkafka-topics --version\n\n# List all topics\nkafka-topics --zookeeper ke-cp-zookeeper-headless:2181 --list\n\n# Create the topic\nkafka-topics --zookeeper ke-cp-zookeeper-headless:2181 --topic telemetry_data --create --partitions 3 --replication-factor 1 --if-not-exists\n\n# Describe a topic\nkafka-topics --describe --topic smap_samhi --zookeeper ke-cp-zookeeper-headless:2181\n\nkafka-configs --bootstrap-server ke-cp-kafka-headless:9092 --entity-type brokers --entity-default --describe\n\nkafka-configs --zookeeper ke-cp-zookeeper-headless:2181 --entity-type topics --entity-name telemetry_data --describe\n\n# Add config\nkafka-configs --zookeeper ke-cp-zookeeper-headless:2181 --entity-type topics --entity-name telemetry_data --alter --add-config retention.ms=604800000\n\nkafka-configs --zookeeper ke-cp-zookeeper-headless:2181 --entity-type topics --entity-name druid_telemetry_data --alter --add-config retention.ms=172800000\n\nkafka-configs --zookeeper ke-cp-zookeeper-headless:2181 --entity-type topics --entity-name test_telemetry_data --alter --add-config retention.ms=172800000\n\nkafka-configs --zookeeper ke-cp-zookeeper-headless:2181 --entity-type topics --entity-name dev_druid_telemetry_data --alter --add-config retention.ms=172800000\n\n# Add partitions\nkafka-topics --zookeeper ke-cp-zookeeper-headless:2181 --alter --topic smap_samhi --partitions 3\n\n## sh add_partitions.sh\n\n# !/bin/bash\nVAL="$(kafka-topics --zookeeper ke-cp-zookeeper-headless:2181 --list | grep druid)"\n\nfor i in $VAL\ndo\nkafka-topics --zookeeper ke-cp-zookeeper-headless:2181 --alter --topic $i --partitions 3\ndone\n\n# Create a message\nMESSAGE="`date -u`"\n\n# Produce a test message to the topic\necho "$MESSAGE" | kafka-console-producer --broker-list ke-cp-kafka-headless:9092 --topic ke-topic\n\n# Consume a test message from the topic\nkafka-console-consumer --bootstrap-server ke-cp-kafka-headless:9092 --topic bench_data --max-messages 1\n\nkafka-console-consumer --bootstrap-server ke-cp-kafka-headless:9092 --topic test_telemetry_data\n\nkafka-console-consumer --bootstrap-server ke-cp-kafka.kafka:9092 --topic test_telemetry_data\n\nkafka-console-consumer --bootstrap-server ke-cp-kafka-external-0:31090,ke-cp-kafka-external-1:31091,ke-cp-kafka-external-2:31092 --topic test_telemetry_data\n\nkafka-console-consumer --bootstrap-server ke-cp-kafka-headless:9092 --topic telemetry_data\n\nkafka-console-consumer --bootstrap-server ke-cp-kafka-headless:9092 --topic druid_telemetry_data --from-beginning\n\n# consume first message from kafka topic\n./kafka-console-consumer --bootstrap-server ke-cp-kafka-headless:9092 --topic druid_telemetry_data_Samhi --from-beginning --max-messages 1\n\n# number of messages in a topic in apache kafka\n./kafka-run-class kafka.tools.GetOffsetShell --broker-list ke-cp-kafka-headless:9092 --topic druid_telemetry_data_Samhi --time -1 --offsets 1 | awk -F ":" \'{sum += $3} END {print sum}\'\n\n## Kafka Consumer Group\ncd /usr/bin\n- kafka-consumer-groups --bootstrap-server ke-cp-kafka-headless:9092 --list\n- ./kafka-consumer-groups --bootstrap-server ke-cp-kafka-headless:9092 --describe --group kafka_prod_to_staging --members --verbose\n- kafka-consumer-groups --bootstrap-server ke-cp-kafka-headless:9092 --describe --group kafka_prod_to_staging --offsets\n- kafka-consumer-groups --bootstrap-server ke-cp-kafka-headless:9092 --describe --group kafka_prod_to_staging --offsets --verbose\n- kafka-consumer-groups --bootstrap-server ke-cp-kafka-headless:9092 --delete --group kafka_archiver_consumer_group\n\n## Kafka Log Storage Directory\n\n/var/lib/kafka/data-0/kafka-log0/\n'})}),"\n",(0,t.jsx)(a.p,{children:(0,t.jsx)(a.a,{href:"https://kafka.apache.org/quickstart",children:"https://kafka.apache.org/quickstart"})}),"\n",(0,t.jsx)(a.p,{children:(0,t.jsx)(a.a,{href:"https://gist.github.com/sam95/d7aed31770883bd272728ad0483629d4",children:"https://gist.github.com/sam95/d7aed31770883bd272728ad0483629d4"})}),"\n",(0,t.jsx)(a.h2,{id:"others",children:"Others"}),"\n",(0,t.jsxs)(a.ul,{children:["\n",(0,t.jsxs)(a.li,{children:[(0,t.jsx)(a.a,{href:"https://docs.oracle.com/javase/8/docs/technotes/tools/unix/keytool.html",children:"keytool"})," - Manages a keystore (database) of cryptographic keys, X.509 certificate chains, and trusted certificates."]}),"\n"]})]})}function l(e={}){const{wrapper:a}={...(0,r.R)(),...e.components};return a?(0,t.jsx)(a,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}},28453:(e,a,n)=>{n.d(a,{R:()=>s,x:()=>k});var o=n(296540);const t={},r=o.createContext(t);function s(e){const a=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function k(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),o.createElement(r.Provider,{value:a},e.children)}}}]);