"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[52976],{792182:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"technologies/kafka/kafka-guarantees","title":"Kafka Guarantees","description":"Message Processing Guarantees","source":"@site/docs/technologies/kafka/kafka-guarantees.md","sourceDirName":"technologies/kafka","slug":"/technologies/kafka/kafka-guarantees","permalink":"/technologies/kafka/kafka-guarantees","draft":false,"unlisted":false,"editUrl":"https://github.com/rajacsp/rajacsp.github.io/tree/master/docs/technologies/kafka/kafka-guarantees.md","tags":[],"version":"current","lastUpdatedBy":"Raja CSP Raman","lastUpdatedAt":1765093505000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Kafka Consumers","permalink":"/technologies/kafka/kafka-consumers"},"next":{"title":"Kafka Listeners","permalink":"/technologies/kafka/kafka-listeners"}}');var r=s(474848),t=s(28453);const l={},a="Kafka Guarantees",o={},c=[{value:"Message Processing Guarantees",id:"message-processing-guarantees",level:2},{value:"Exactly Once Semantics (EOS)",id:"exactly-once-semantics-eos",level:2},{value:"Key Building Blocks for EOS",id:"key-building-blocks-for-eos",level:3},{value:"(a) Idempotent Producer",id:"a-idempotent-producer",level:4},{value:"(b) Transactions",id:"b-transactions",level:4},{value:"(c) Replication Protocol",id:"c-replication-protocol",level:4},{value:"Putting It Together",id:"putting-it-together",level:3},{value:"Limitations",id:"limitations",level:3},{value:"Replication Protocol",id:"replication-protocol",level:2},{value:"Outbox Pattern",id:"outbox-pattern",level:2},{value:"Problem it Solves",id:"problem-it-solves",level:3},{value:"The Outbox Pattern",id:"the-outbox-pattern",level:3},{value:"Event Relay (Debezium / Polling)",id:"event-relay-debezium--polling",level:3},{value:"Benefits",id:"benefits",level:3},{value:"Example Flow",id:"example-flow",level:3},{value:"Outbox to Kafka - EOS",id:"outbox-to-kafka---eos",level:2},{value:"1. The Challenge",id:"1-the-challenge",level:3},{value:"2. Solution Approaches",id:"2-solution-approaches",level:3},{value:"Approach A: <strong>Kafka Transactions (EOS Producer)</strong>",id:"approach-a-kafka-transactions-eos-producer",level:4},{value:"Approach B: <strong>Idempotent Deduplication Key</strong>",id:"approach-b-idempotent-deduplication-key",level:4},{value:"Approach C: <strong>Debezium / CDC Outbox (Best Practice)</strong>",id:"approach-c-debezium--cdc-outbox-best-practice",level:4},{value:"3. Practical Design (if writing custom relay service)",id:"3-practical-design-if-writing-custom-relay-service",level:3},{value:"4. Key Points",id:"4-key-points",level:3}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"kafka-guarantees",children:"Kafka Guarantees"})}),"\n",(0,r.jsx)(n.h2,{id:"message-processing-guarantees",children:"Message Processing Guarantees"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"No guarantee -"})," No explicit guarantee is provided, so consumers may process messages once, multiple times or never at all."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"At most once -"}),' This is "best effort" delivery semantics. Consumers will receive and process messages exactly once or not at all.']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"At least once -"})," Consumers will receive and process every message, but they may process the same message more than once."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Effectively once -"})," Also ",(0,r.jsx)(n.a,{href:"https://streaml.io/blog/exactly-once",children:"contentiously"})," ",(0,r.jsx)(n.a,{href:"https://medium.com/@jaykreps/exactly-once-support-in-apache-kafka-55e1fdd0a35f",children:"known"})," as exactly once, this promises consumers will process every message once."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"image",src:s(438025).A+"",width:"525",height:"409"})}),"\n",(0,r.jsx)(n.h2,{id:"exactly-once-semantics-eos",children:"Exactly Once Semantics (EOS)"}),"\n",(0,r.jsx)(n.h3,{id:"key-building-blocks-for-eos",children:"Key Building Blocks for EOS"}),"\n",(0,r.jsxs)(n.p,{children:["Kafka achieves ",(0,r.jsx)(n.strong,{children:"EOS"})," using three main features:"]}),"\n",(0,r.jsx)(n.h4,{id:"a-idempotent-producer",children:"(a) Idempotent Producer"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Every message sent by a producer gets a ",(0,r.jsx)(n.strong,{children:"producer ID (PID)"})," and a ",(0,r.jsx)(n.strong,{children:"sequence number"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"If retries happen (e.g., network glitch), Kafka detects duplicates by checking the sequence number and ignores them."}),"\n",(0,r.jsxs)(n.li,{children:["Ensures ",(0,r.jsx)(n.strong,{children:"no duplicates on retries"})," \u2192 gives ",(0,r.jsx)(n.strong,{children:"idempotent writes"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"b-transactions",children:"(b) Transactions"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["A producer can group multiple writes (to one or more partitions, topics) into a ",(0,r.jsx)(n.strong,{children:"transaction"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Kafka ensures that either:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"All writes in the transaction are committed, or"}),"\n",(0,r.jsx)(n.li,{children:"None are (atomicity)."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Consumers using ",(0,r.jsx)(n.strong,{children:"read_committed"})," isolation see only committed data."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"c-replication-protocol",children:"(c) Replication Protocol"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["With ",(0,r.jsx)(n.code,{children:"acks=all"}),", Kafka ensures that once a transaction is committed, it\u2019s ",(0,r.jsx)(n.strong,{children:"durably replicated to all in-sync replicas (ISRs)"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"This guarantees durability even if the leader fails immediately after commit."}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"putting-it-together",children:"Putting It Together"}),"\n",(0,r.jsx)(n.p,{children:"Here\u2019s how EOS works in practice:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Producer"})," starts a transaction \u2192 ",(0,r.jsx)(n.code,{children:"initTransactions()"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Writes messages with ",(0,r.jsx)(n.strong,{children:"idempotence enabled"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Calls ",(0,r.jsx)(n.code,{children:"commitTransaction()"})," \u2192 Kafka writes a ",(0,r.jsx)(n.strong,{children:"transaction marker"})," ensuring atomic visibility."]}),"\n",(0,r.jsxs)(n.li,{children:["Messages are replicated to all ISRs (with ",(0,r.jsx)(n.code,{children:"acks=all"}),")."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Consumer"})," reads with ",(0,r.jsx)(n.code,{children:"isolation.level=read_committed"})," \u2192 sees each committed message ",(0,r.jsx)(n.strong,{children:"exactly once"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"limitations",children:"Limitations"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["EOS works ",(0,r.jsx)(n.strong,{children:"only within Kafka"})," (end-to-end with producers + Kafka + consumers)."]}),"\n",(0,r.jsxs)(n.li,{children:["If you write to an external DB/system, you need ",(0,r.jsx)(n.strong,{children:"two-phase commit or outbox patterns"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Slight overhead due to transaction coordination."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"replication-protocol",children:"Replication Protocol"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["When a ",(0,r.jsx)(n.strong,{children:"producer"})," writes a message to a partition, it first goes to the ",(0,r.jsx)(n.strong,{children:"leader replica"})," of that partition."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["The producer can specify the ",(0,r.jsx)(n.strong,{children:"acks"})," setting:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"acks=0"})," \u2192 Producer doesn\u2019t wait for acknowledgment."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"acks=1"})," \u2192 Producer gets an acknowledgment once the leader writes it."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"acks=all"})," (or ",(0,r.jsx)(n.code,{children:"-1"}),") \u2192 Producer gets acknowledgment only after the message is written to the leader ",(0,r.jsx)(n.strong,{children:"and"})," replicated to all ",(0,r.jsx)(n.strong,{children:"in-sync replicas (ISRs)"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Important nuance"}),": Kafka does ",(0,r.jsx)(n.strong,{children:"not"})," guarantee replication to ",(0,r.jsx)(n.em,{children:"all available replicas"})," after the leader write. Instead, it guarantees replication to the set of ",(0,r.jsx)(n.strong,{children:"in-sync replicas (ISRs)"}),"."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["If a follower is ",(0,r.jsx)(n.strong,{children:"out of sync"}),", it won\u2019t block the acknowledgment."]}),"\n",(0,r.jsx)(n.li,{children:"As long as at least one ISR (typically the leader + followers in sync) has the message, Kafka considers it durable."}),"\n"]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["Kafka\u2019s replication protocol guarantees that once a message has been acknowledged with ",(0,r.jsx)(n.code,{children:"acks=all"}),", it has been written successfully to the leader replica and replicated to all in-sync replicas (ISRs)."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"outbox-pattern",children:"Outbox Pattern"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.strong,{children:"Outbox Pattern"})," is one of the most popular patterns used to achieve ",(0,r.jsx)(n.strong,{children:"reliable event-driven integration"})," between a database (like MySQL, PostgreSQL) and a message broker (like Kafka)."]}),"\n",(0,r.jsx)(n.h3,{id:"problem-it-solves",children:"Problem it Solves"}),"\n",(0,r.jsx)(n.p,{children:"When a service needs to:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Update its ",(0,r.jsx)(n.strong,{children:"own database"})," (say insert a new ",(0,r.jsx)(n.code,{children:"Order"}),"), and"]}),"\n",(0,r.jsxs)(n.li,{children:["Publish an ",(0,r.jsx)(n.strong,{children:"event to Kafka"})," (like ",(0,r.jsx)(n.code,{children:"OrderCreated"}),")"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["You run into the ",(0,r.jsx)(n.strong,{children:"dual-write problem"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"If you write to the DB but crash before publishing to Kafka \u2192 event is lost."}),"\n",(0,r.jsx)(n.li,{children:"If you publish to Kafka but crash before writing to DB \u2192 system state is inconsistent."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["This breaks ",(0,r.jsx)(n.strong,{children:"exactly-once semantics across DB + Kafka"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"the-outbox-pattern",children:"The Outbox Pattern"}),"\n",(0,r.jsxs)(n.p,{children:["Instead of doing both separately, you write ",(0,r.jsx)(n.strong,{children:"only to your database"})," in a single atomic transaction:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Service writes ",(0,r.jsx)(n.strong,{children:"business data"})," (e.g., new ",(0,r.jsx)(n.code,{children:"Order"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:["In the ",(0,r.jsx)(n.strong,{children:"same transaction"}),", service writes an ",(0,r.jsx)(n.strong,{children:"event record"})," into a special ",(0,r.jsx)(n.code,{children:"outbox"})," table."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Example (Postgres/MySQL):"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"BEGIN;\nINSERT INTO orders (id, customer, amount, status) VALUES (123, 'CSP', 1000, 'CREATED');\nINSERT INTO outbox (event_id, type, payload, status) VALUES (uuid(), 'OrderCreated', '{\"id\":123,\"amount\":1000}', 'NEW');\nCOMMIT;\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Now DB and event are ",(0,r.jsx)(n.strong,{children:"guaranteed consistent"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"event-relay-debezium--polling",children:"Event Relay (Debezium / Polling)"}),"\n",(0,r.jsx)(n.p,{children:"Next step:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["A ",(0,r.jsx)(n.strong,{children:"relay process"})," reads events from the ",(0,r.jsx)(n.code,{children:"outbox"})," table and publishes them to Kafka."]}),"\n",(0,r.jsxs)(n.li,{children:["Can be done via:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Change Data Capture (CDC)"})," tools like ",(0,r.jsx)(n.strong,{children:"Debezium"})," (reads DB transaction log, automatically streams outbox rows to Kafka)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Polling"})," (a background service queries the outbox table and sends events)."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["After publishing, event status can be marked as ",(0,r.jsx)(n.code,{children:"SENT"})," or the row can be archived."]}),"\n",(0,r.jsx)(n.h3,{id:"benefits",children:"Benefits"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Atomicity"})," \u2192 DB update + event log are one transaction."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reliability"})," \u2192 No lost or duplicated events."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Event-driven architecture"})," works smoothly with existing DB."]}),"\n",(0,r.jsxs)(n.li,{children:["Plays well with ",(0,r.jsx)(n.strong,{children:"Kafka + EOS"})," when you integrate external systems."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"example-flow",children:"Example Flow"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Order Service"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"User places order."}),"\n",(0,r.jsx)(n.li,{children:"Service saves order + inserts event into outbox table."}),"\n",(0,r.jsxs)(n.li,{children:["Debezium streams outbox \u2192 Kafka topic ",(0,r.jsx)(n.code,{children:"order.events"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Inventory Service"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Consumes from ",(0,r.jsx)(n.code,{children:"order.events"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Updates stock accordingly."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"outbox-to-kafka---eos",children:"Outbox to Kafka - EOS"}),"\n",(0,r.jsx)(n.h3,{id:"1-the-challenge",children:"1. The Challenge"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["The ",(0,r.jsx)(n.strong,{children:"outbox table"})," is already atomic with your business data."]}),"\n",(0,r.jsxs)(n.li,{children:["But when your ",(0,r.jsx)(n.strong,{children:"producer service"})," reads from the outbox and publishes to Kafka, two risks appear:","\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Duplicate sends"})," (retry on failure, service crash before marking event as sent)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Lost events"})," (service marks row as sent, but crash happens before actually producing to Kafka)."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"We need EOS here."}),"\n",(0,r.jsx)(n.h3,{id:"2-solution-approaches",children:"2. Solution Approaches"}),"\n",(0,r.jsxs)(n.h4,{id:"approach-a-kafka-transactions-eos-producer",children:["Approach A: ",(0,r.jsx)(n.strong,{children:"Kafka Transactions (EOS Producer)"})]}),"\n",(0,r.jsxs)(n.p,{children:["Kafka has ",(0,r.jsx)(n.strong,{children:"idempotent producers + transactions"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Configure the producer with:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"enable.idempotence=true"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"acks=all"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"transactional.id=outbox-relay-1"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Start a ",(0,r.jsx)(n.strong,{children:"transaction"}),":","\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Read batch of unsent events from outbox table."}),"\n",(0,r.jsx)(n.li,{children:"Begin Kafka transaction."}),"\n",(0,r.jsx)(n.li,{children:"Send all events to Kafka."}),"\n",(0,r.jsxs)(n.li,{children:["Commit Kafka transaction ",(0,r.jsx)(n.strong,{children:"AND"})," update outbox table status (",(0,r.jsx)(n.code,{children:"sent=true"}),") in the ",(0,r.jsx)(n.strong,{children:"same transactional flow"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["\ud83d\udc49 But here\u2019s the catch: Kafka transactions and DB transactions are separate. You ",(0,r.jsx)(n.strong,{children:"cannot"})," commit both atomically in one step."]}),"\n",(0,r.jsxs)(n.p,{children:["So you need a ",(0,r.jsx)(n.strong,{children:"transactional outbox + idempotent updates"})," pattern."]}),"\n",(0,r.jsxs)(n.h4,{id:"approach-b-idempotent-deduplication-key",children:["Approach B: ",(0,r.jsx)(n.strong,{children:"Idempotent Deduplication Key"})]}),"\n",(0,r.jsxs)(n.p,{children:["Each event in outbox has a ",(0,r.jsx)(n.strong,{children:"unique event_id (UUID)"}),"."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.code,{children:"event_id"})," as ",(0,r.jsx)(n.strong,{children:"Kafka message key"})," (or put it in headers)."]}),"\n",(0,r.jsx)(n.li,{children:"Kafka producer with idempotence ensures retries don\u2019t create duplicates."}),"\n",(0,r.jsxs)(n.li,{children:["Consumers can deduplicate by ",(0,r.jsx)(n.code,{children:"event_id"})," if needed."]}),"\n"]}),"\n",(0,r.jsxs)(n.h4,{id:"approach-c-debezium--cdc-outbox-best-practice",children:["Approach C: ",(0,r.jsx)(n.strong,{children:"Debezium / CDC Outbox (Best Practice)"})]}),"\n",(0,r.jsx)(n.p,{children:"Instead of writing custom relay code:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Use ",(0,r.jsx)(n.strong,{children:"Debezium"})," (reads DB\u2019s transaction log)."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"When your service commits the DB transaction (business row + outbox row), Debezium streams the outbox change directly into Kafka."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["This is already ",(0,r.jsx)(n.strong,{children:"exactly-once"})," because:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"DB transaction log guarantees no duplicates."}),"\n",(0,r.jsx)(n.li,{children:"Kafka\u2019s EOS producer (in Debezium) guarantees idempotence."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:'This avoids the "dual-write" problem entirely.'}),"\n",(0,r.jsx)(n.h3,{id:"3-practical-design-if-writing-custom-relay-service",children:"3. Practical Design (if writing custom relay service)"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Outbox row has:\n",(0,r.jsx)(n.code,{children:"event_id (UUID, PK), payload, status, created_at"})]}),"\n",(0,r.jsxs)(n.li,{children:["Relay service logic:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Poll outbox rows where ",(0,r.jsx)(n.code,{children:"status='NEW'"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Start Kafka transaction."}),"\n",(0,r.jsxs)(n.li,{children:["For each row:\n",(0,r.jsx)(n.code,{children:'producer.send(new ProducerRecord("topic", event_id, payload));'})]}),"\n",(0,r.jsx)(n.li,{children:"Commit Kafka transaction."}),"\n",(0,r.jsxs)(n.li,{children:["After successful commit, mark those rows as ",(0,r.jsx)(n.code,{children:"SENT"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["If crash happens:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Rows still marked ",(0,r.jsx)(n.code,{children:"NEW"})," \u2192 safe to retry."]}),"\n",(0,r.jsx)(n.li,{children:"Kafka idempotence + unique key ensure no duplicates."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"4-key-points",children:"4. Key Points"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Idempotence in Kafka"})," removes duplicates caused by retries."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Outbox status column"})," ensures no message is lost."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"CDC (Debezium)"})," is the cleanest and production-proven way."]}),"\n",(0,r.jsxs)(n.li,{children:["If you roll your own relay, you must use ",(0,r.jsx)(n.strong,{children:"idempotent producer + unique event_id"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["\ud83d\udc49 So, ",(0,r.jsx)(n.strong,{children:"the safest way"})," to ensure EOS from Outbox \u2192 Kafka is:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.strong,{children:"CDC (Debezium Outbox pattern)"})," if possible."]}),"\n",(0,r.jsxs)(n.li,{children:["If using a custom service, use ",(0,r.jsx)(n.strong,{children:"Kafka idempotent producer with unique event_id"})," + mark rows after commit."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},438025:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/Technologies-Kafka-Others-image1-c116dd5d2221e9d4fc3d59d6c2a42a56.jpg"},28453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>a});var i=s(296540);const r={},t=i.createContext(r);function l(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);